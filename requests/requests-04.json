[
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "Computational efficiency and theoretical limits of sequence modeling."
    },
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "Methods for encoding sequential order in non-recurrent architectures."
    },
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "The practical challenges and solutions for stabilizing dot-product attention."
    },
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "Enhancing representational power through parallel, subspace-specific attention."
    },
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "The role of regularization and optimization schemes in training large-scale models."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "The LLM as a substitute for evolutionary operators."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "The article's perspective on the theme of black-box optimization."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "The application of multi-objective evolutionary principles throughout the surveyed research."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "The dual role of the LLM-EA synergy in the context of model and code security."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "Neural Architecture Search (NAS) as both a target for optimization and a domain for synergy."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "The paradox of high accuracy as an indicator of fragility."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "The impact of model scale on overfitting vulnerability."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "Differential robustness across distinct LLM architectural families."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "The methodology of using generative models to create adversarial evaluation datasets."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "The paper's critique of a leaderboard-centric evaluation culture in NLP."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "Emergent dimensionality hierarchy in a trained reasoning model as a parallel to the functional organization of the mouse cortex."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "Novel training strategies for recurrent architectures, combining BPTT-free approximate gradients, deep supervision, and reinforcement learning for adaptive computation."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "An argument against the architectural and computational limitations of the Transformer/Chain-of-Thought paradigm for genuine, latent algorithmic reasoning."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "Applying principles of hierarchical processing, temporal separation, and local credit assignment from neuroscience to engineer stable, deep reasoning in artificial neural networks."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "Mechanisms for achieving and leveraging effective computational depth, using \"hierarchical convergence\" to overcome the vanishing gradient and premature convergence problems in recurrent systems."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "The role and limitations of proprietary expert models in synthetic data generation for LLM research."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "Efficiency trade-offs in LLM data augmentation strategies."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "A framework for categorizing mathematical reasoning skills in language models, from basic forward reasoning to complex reflective capabilities."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "Comparing instance-dimension vs. sequence-dimension data augmentation for enhancing LLM reasoning."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "The interplay between data quantity, quality, and complexity in fine-tuning language models for mathematical tasks."
    },
    {
        "article": "articles/MemOS.md",
        "query": "The framework for accountable and governed memory in multi-agent systems."
    },
    {
        "article": "articles/MemOS.md",
        "query": "Mechanisms for the lifecycle and cross-type transformation of memory."
    },
    {
        "article": "articles/MemOS.md",
        "query": "The role of structured metadata in enabling the scheduling, governance, and evolution of memory."
    },
    {
        "article": "articles/MemOS.md",
        "query": "The vision for a collaborative and decentralized memory sharing ecosystem."
    },
    {
        "article": "articles/MemOS.md",
        "query": "Parallels between the MemOS architecture and cognitive models of memory."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "The asymmetric nature of the loss landscape around a random initialization."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "How random teacher distillation pre-conditions a network for supervised training."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "The role of the input data distribution in shaping the learned representations."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "The impact of student initialization proximity to the teacher."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "The nature of implicit regularization induced by the teacher-student dynamics."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "Causes of optimization instability and performance degradation during RL fine-tuning of small language models."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "The impact of output length constraints on the stability and efficacy of training LLMs for complex reasoning tasks."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "Strategies for curating compact datasets by balancing problem difficulty to enhance RL training efficiency under resource constraints."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "The challenge of managing multilingual language drift when fine-tuning a foundational model for a monolingual reasoning task."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "A comparative economic analysis of achieving state-of-the-art reasoning performance in small vs. large language models."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "The influence of a model's pretrained latent abilities (like code reasoning) on the outcomes of reinforcement learning, irrespective of the reward signal's quality."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "A critique of model-specific conclusions in RL research, using the Qwen model family as a case study for how easily performance gains can be achieved with spurious signals."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "The role of optimization algorithm artifacts, specifically the clipping mechanism in GRPO, in creating a directional training signal from pure noise."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "The divergent behaviors of different model families (Qwen, Llama, OLMo) under identical RLVR training, highlighting a fundamental lack of technique generalization."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "The geometric interpretation of task interference through singular vector alignment."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "The counter-intuitive necessity of low-rank approximation for effective interference reduction."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "An argument for structure-aware model manipulation over flattened parameter approaches."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "The application of Orthogonal Procrustes analysis to decorrelate task-specific feature bases."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "The paper's empirical argument for eliminating the scaling coefficient hyperparameter."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "The paper as a solution to the geometric unidentifiability of representation spaces, resolved by imposing a causal structure."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "How the proposed 'causal inner product' serves as a bridge to unify the conceptually separate input (embedding) and output (unembedding) representation spaces."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "The derivation of a semantically meaningful geometry from the statistical properties of the model's full vocabulary, rather than from its training data distribution."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "The article's use of counterfactuals as a formal language to ground and connect disparate intuitions about linear representations."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "Providing a single geometric framework that formally connects the subspace hypothesis (e.g., word2vec analogies) with the practical techniques of linear probing and activation steering."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "The progressive constraint strategy in knowledge distillation."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "Rationale for the staged training methodology."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "The paper's dual approach to the engineering problem of embedding dimensionality."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "Methodology for fusing knowledge from heterogeneous teacher models."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "Self-distillation as a mechanism for post-hoc modality alignment."
    },
    {
        "article": "articles/rStar-Math.md",
        "query": "The role of code execution as a verifier for synthetic reasoning data."
    },
    {
        "article": "articles/rStar-Math.md",
        "query": "Novel training methodologies for process reward models that bypass noisy score annotation."
    },
    {
        "article": "articles/rStar-Math.md",
        "query": "The viability of self-evolution as an alternative to knowledge distillation for creating state-of-the-art training datasets."
    },
    {
        "article": "articles/rStar-Math.md",
        "query": "The emergence of self-correction capabilities as an intrinsic byproduct of the MCTS-based reasoning process."
    }
]
